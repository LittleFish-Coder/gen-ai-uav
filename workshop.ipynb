{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI CUP 2024 Spring\n",
    "\n",
    "Official hands-on workshop for [AI CUP 2024 Spring - GenAI UAV.](https://tbrain.trendmicro.com.tw/Competitions/Details/34)\n",
    "\n",
    "- Team ID: TEAM_5333\n",
    "- Place: 18(Public), 13 (Private)\n",
    "- Member:\n",
    "    - Chen-Yang Yu, NCKU (Leader)\n",
    "    - Yuan-Chun Chiang, NTU\n",
    "    - Yu-Hao Chiang, NCKU \n",
    "    - Xin-Xian Lin, NCKU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "We will cover the following topics in this workshop to reproduce our best result.\n",
    "\n",
    "0. Install Environment\n",
    "1. Data Preparasion\n",
    "2. Train Model (Optional, pre-trained weight is provided)\n",
    "3. Test Model (Inference)\n",
    "4. Transform the results into AI CUP format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if `pytorch-CycleGAN-and-pix2pix` is already cloned\n",
    "if not os.path.exists('pytorch-CycleGAN-and-pix2pix'):\n",
    "    !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "else:\n",
    "    print('pytorch-CycleGAN-and-pix2pix is already cloned.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparasion\n",
    "\n",
    "we will do the following steps to prepare the data.\n",
    "\n",
    "- 1.1 Download the dataset\n",
    "- 1.2 Prepare Raw Training Data\n",
    "- 1.3 Prepare Raw Testing Data\n",
    "- 1.4 Prepare 2 domain-specific datasets (Road and River)\n",
    "- 1.5 Copy the dataset to the pytorch-CycleGAN-and-pix2pix dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to `./dataset`\n",
    "os.chdir('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "The script will download the dataset if you haven't downloaded it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ../scripts/download_official_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Raw Training Data\n",
    "The Training dataset contains two subfolder:\n",
    "- label_img: contains the draft images\n",
    "- img: contains the corresponding ground truth images (drone image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "train_dataset_zip = '34_Competition 1_Training dataset.zip'\n",
    "\n",
    "# unzip the train_dataset_zip\n",
    "with zipfile.ZipFile(train_dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'training_dataset'\n",
    "# rename the extracted folder\n",
    "os.rename('Training dataset', train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './training_dataset'\n",
    "print(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the subfolders as trainA and trainB\n",
    "mapping the folder name to the model input:\n",
    "- `training_dataset/label_img` -> `training_dataset/trainA`\n",
    "- `training_dataset/img` -> `training_dataset/trainB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the subfolders\n",
    "os.rename(train_dir + '/label_img', train_dir + '/trainA')\n",
    "os.rename(train_dir + '/img', train_dir + '/trainB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align trainA and trainB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python align_dataset.py --source_folder training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Raw Public and Private Testing Data\n",
    "1. The extracted zip file only contains `label_img` folder\n",
    "2. so we need to create the parent folder `testing_dataset`\n",
    "3. and move the `label_img` folder to `testing_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "public_testing_dataset_zip = '34_Competition 1_public testing dataset.zip'\n",
    "private_testing_dataset_zip = '34_Competition 1_Private Test Dataset.zip'\n",
    "test_dir = 'testing_dataset'\n",
    "\n",
    "# unzip the public testing dataset\n",
    "with zipfile.ZipFile(public_testing_dataset_zip, 'r') as zip_ref:\n",
    "\tzip_ref.extractall(test_dir)\n",
    "\n",
    "# unzip the private testing dataset\n",
    "with zipfile.ZipFile(private_testing_dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'testing_dataset'\n",
    "print(os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the subfolder as testA\n",
    "\n",
    "since the ground truth images are not provided, we just need to rename the folder `label_img` as `testA`\n",
    "\n",
    "mapping the folder name to the model input:\n",
    "- `testing_dataset/label_img` -> `testing_dataset/testA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(test_dir + '/label_img', test_dir + '/testA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare 2 domain-specific datasets (Road and River)\n",
    "\n",
    "We are going to create 4 folders in this session:\n",
    "```\n",
    "dataset\n",
    "├── test_ROAD\n",
    "│   └── testA\n",
    "├── test_RIVER\n",
    "│   └── testA\n",
    "├── train_ROAD\n",
    "|   ├── train\n",
    "│   ├── trainA\n",
    "│   └── trainB\n",
    "└── train_RIVER\n",
    "    ├── train\n",
    "    ├── trainA\n",
    "    └── trainB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Images from Raw Training Data\n",
    "Each `trainA` and `trainB` subfolders contains 2 types of images:\n",
    "- River images(e.g. TRA_RI_1000000.png)\n",
    "- Road images(e.g. TRA_RO_1000000.png)\n",
    "\n",
    "so we need to create 2 folders:\n",
    "- River (contains `trainA` and `trainB` subfolders, each contains river images)\n",
    "- Road (contains `trainA` and `trainB` subfolders, each contains road images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'training_dataset'\n",
    "train_river_dir = 'train_RIVER'\n",
    "train_road_dir = 'train_ROAD'\n",
    "\n",
    "# create the folders\n",
    "if not os.path.exists(train_river_dir):\n",
    "\tos.makedirs(train_river_dir)\n",
    "if not os.path.exists(train_road_dir):\n",
    "\tos.makedirs(train_road_dir)\n",
    "\n",
    "for subdir in os.listdir(train_dir):\n",
    "\t# create the subfolders if not exist\n",
    "\tif not os.path.exists(train_river_dir + '/' + subdir):\n",
    "\t\tos.makedirs(train_river_dir + '/' + subdir)\n",
    "\tif not os.path.exists(train_road_dir + '/' + subdir):\n",
    "\t\tos.makedirs(train_road_dir + '/' + subdir)\n",
    "\t\n",
    "\t# move or copy the files\n",
    "\tfor file in os.listdir(train_dir + '/' + subdir):\n",
    "\t\tif '_RI_' in file:\n",
    "\t\t\tshutil.copy(train_dir + '/' + subdir + '/' + file, train_river_dir + '/' + subdir + '/' + file)\n",
    "\t\telif '_RO_' in file:\n",
    "\t\t\tshutil.copy(train_dir + '/' + subdir + '/' + file, train_road_dir + '/' + subdir + '/' + file)\n",
    "\t\telse:\n",
    "\t\t\tprint('ERROR: file name not recognized: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Images from Raw Testing Data\n",
    "`testing_dataset/testA` subfolder contains 2 types of images:\n",
    "- River images(e.g. PUB_RI_1000000.png or PRI_RI_1000000.png)\n",
    "- Road images(e.g. PUB_RO_1000459.png or PRI_RO_1000459.png)\n",
    "\n",
    "so we need to create 2 folders:\n",
    "- test_RIVER (contains `testA` subfolders, only contains river images)\n",
    "- test_ROAD (contains `testA` subfolders, only contains road images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "test_dir = 'testing_dataset'\n",
    "test_river_dir = 'test_RIVER'\n",
    "test_road_dir = 'test_ROAD'\n",
    "\n",
    "# create the folders\n",
    "if not os.path.exists(test_river_dir):\n",
    "\tos.makedirs(test_river_dir)\n",
    "if not os.path.exists(test_road_dir):\n",
    "\tos.makedirs(test_road_dir)\n",
    " \n",
    "\n",
    "for subdir in os.listdir(test_dir):\n",
    "\t# create the subfolders if not exist\n",
    "\tif not os.path.exists(test_river_dir + '/' + subdir):\n",
    "\t\tos.makedirs(test_river_dir + '/' + subdir)\n",
    "\tif not os.path.exists(test_road_dir + '/' + subdir):\n",
    "\t\tos.makedirs(test_road_dir + '/' + subdir)\n",
    "\t\n",
    "\t# move or copy the files\n",
    "\tfor file in os.listdir(test_dir + '/' + subdir):\n",
    "\t\tif '_RI_' in file:\n",
    "\t\t\tshutil.copy(test_dir + '/' + subdir + '/' + file, test_river_dir + '/' + subdir + '/' + file)\n",
    "\t\telif '_RO_' in file:\n",
    "\t\t\tshutil.copy(test_dir + '/' + subdir + '/' + file, test_road_dir + '/' + subdir + '/' + file)\n",
    "\t\telse:\n",
    "\t\t\tprint('ERROR: file name not recognized: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the dataset to the pytorch-CycleGAN-and-pix2pix dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Train\n",
    "\n",
    "move the `train_RIVER` and `train_ROAD` folders to `../pytorch-CycleGAN-and-pix2pix/datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the folder to target folder\n",
    "target_dir = '../pytorch-CycleGAN-and-pix2pix/datasets'\n",
    "shutil.copytree(train_river_dir, target_dir + '/' + train_river_dir)\n",
    "shutil.copytree(train_road_dir, target_dir + '/' + train_road_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Test\n",
    "\n",
    "copy the `test_RIVER` and `test_ROAD` folders to `../pytorch-CycleGAN-and-pix2pix/datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the folder to target folder\n",
    "target_dir = '../pytorch-CycleGAN-and-pix2pix/datasets'\n",
    "shutil.copytree(test_river_dir, target_dir + '/' + test_river_dir)\n",
    "shutil.copytree(test_road_dir, target_dir + '/' + test_road_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the working directory\n",
    "os.chdir('..')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('./pytorch-CycleGAN-and-pix2pix')\n",
    "except FileNotFoundError:\n",
    "    print(\"Already in the correct directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2 domain-specific models\n",
    "- one for RIVER\n",
    "- one for ROAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n",
    "\n",
    "(We have finished this part at the previous sessiona)\n",
    "\n",
    "Each dataset should have the following directory structure:\n",
    "\n",
    "```\n",
    "datasets\n",
    "├── train_ROAD\n",
    "|   ├── train\n",
    "│   ├── trainA\n",
    "│   └── trainB\n",
    "└── train_RIVER\n",
    "    ├── train\n",
    "    ├── trainA\n",
    "    └── trainB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Arguments\n",
    "\n",
    "- `--n_epochs`: 200 (default 100)\n",
    "- `--n_epochs_decay`: 200 (default 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the n_epochs and n_epochs_decay parameters up to total 400 epochs for each model\n",
    "! python train.py --dataroot ./datasets/train_ROAD --name ROAD_pix2pix --model pix2pix --direction AtoB --n_epochs 200 --n_epochs_decay 200 --display_id 0 --continue_train\n",
    "! python train.py --dataroot ./datasets/train_RIVER --name RIVER_pix2pix --model pix2pix --direction AtoB --n_epochs 200 --n_epochs_decay 200 --display_id 0 --continue_train\n",
    "\n",
    "# use nohup to run the training in the background\n",
    "# ! nohup python train.py ... > road.log &\t\n",
    "# ! nohup python train.py ... > river.log &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results\n",
    "after training, you can find the results in \n",
    "- `pytorch-CycleGAN-and-pix2pix/checkpoints/ROAD_pix2pix` folder\n",
    "- `pytorch-CycleGAN-and-pix2pix/checkpoints/RIVER_pix2pix` folder\n",
    "\n",
    "Each folder contains:\n",
    "- `/web/index.html` for the visualization of the results\n",
    "- `latest_net_G.pth` for the latest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test Model (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('./pytorch-CycleGAN-and-pix2pix')\n",
    "except FileNotFoundError:\n",
    "    print(\"Already in the correct directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n",
    "\n",
    "(We have finished this part at the previous session)\n",
    "\n",
    "Each dataset should have the following directory structure:\n",
    "\n",
    "```\n",
    "datasets\n",
    "├── test_ROAD\n",
    "│   └── testA\n",
    "├── test_RIVER\n",
    "│   └── testA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the weights\n",
    "After training, you should have a folder with the weights of the model. \n",
    "\n",
    "It should be located in the `pytorch-CycleGAN-and-pix2pix/checkpoints` folder.\n",
    "\n",
    "For example, in our previous training, we have the following weights:\n",
    "- `checkpoints/ROAD_pix2pix/latest_net_G.pth`\n",
    "- `checkpoints/RIVER_pix2pix/latest_net_G.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is no pre-trained model, use our pre-trained model\n",
    "if not os.path.exists('./checkpoints/ROAD_pix2pix') or not os.path.exists('./checkpoints/RIVER_pix2pix'):\n",
    "    !bash ../scripts/download_pretrained_road_river_weight.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_road_dir = './datasets/test_ROAD/testA'\n",
    "test_river_dir = './datasets/test_RIVER/testA'\n",
    "\n",
    "road_model = 'ROAD_pix2pix'\n",
    "river_model = 'RIVER_pix2pix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with domain-specific models in single mode\n",
    "\n",
    "Use the trained model to inference the testA image\n",
    "\n",
    "Convert the `test_RIVER/testA` and `test_ROAD/testA` images to domainB images\n",
    "\n",
    "- `--dataroot`: the folder where the testing data is located\n",
    "- `--name`: the name of the model\n",
    "- `--mode`l: the model mode\n",
    "- `--netG`: the backbone architecture of the generator\n",
    "- `--direction`: the direction of the model\n",
    "- `--dataset_mod`e: single (which we don't need to prepare the paired data)\n",
    "- `--num_test`: the number of testing data (default is 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the 2 dataset in single mode\n",
    "! python test.py --dataroot {test_road_dir} --name {road_model} --model test --netG unet_256 --direction AtoB --dataset_mode single --norm batch --num_test 10000\n",
    "! python test.py --dataroot {test_river_dir} --name {river_model} --model test --netG unet_256 --direction AtoB --dataset_mode single --norm batch --num_test 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transform the results into AI CUP format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are stored in \n",
    "- `./results/ROAD_pix2pix/test_latest/images/`\n",
    "- `./results/RIVER_pix2pix/test_latest/images/`\n",
    "\n",
    "And there are 2 types of results in each folder:\n",
    "- `{Prefix}_real` (domainA)\n",
    "- `{Prefix}_fake` (domainB)\n",
    "\n",
    "1. Store the `{Prefix}_fake.png` as `{Prefix}.jpg` to `./domain_type/test_latest/submission/`.\n",
    "\n",
    "2. Resize the images as 428x240 (width x height) to match the AI CUP format.\n",
    "\n",
    "3. Store the results of `ROAD` and `RIVER` in the `ROAD_RIVER_combined` folder.\n",
    "\n",
    "3. Finally, zip the `./domain_type/test_latest/submission/` folder and submit it to AI CUP.\n",
    "\n",
    "❗️For resize, we decide to use `INTER_CUBIC` to keep the quality of the images, since we are enlarging the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROAD_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROAD_pix2pix\n",
    "# store the fake images to the `./results/ROAD_pix2pix/test_latest/submission/` folder\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_folder = './results/ROAD_pix2pix/test_latest/images'\n",
    "target_folder = './results/ROAD_pix2pix/test_latest/submission'\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "for image_name in os.listdir(source_folder):\n",
    "    if 'fake' in image_name:\n",
    "        new_name = image_name.replace('_fake.png', '.jpg')\n",
    "        shutil.copy(os.path.join(source_folder, image_name), os.path.join(target_folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image as 428x240\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for image_name in os.listdir(target_folder):\n",
    "    img = cv2.imread(os.path.join(target_folder, image_name))\n",
    "    img = cv2.resize(img, (428, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(os.path.join(target_folder, image_name), img)\n",
    "print(\"Finished resizing images\")\n",
    "print(f\"Size: {len(os.listdir(target_folder))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIVER_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIVER_pix2pix\n",
    "# store the fake images to the `./results/ROAD_pix2pix/test_latest/submission/` folder\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_folder = './results/RIVER_pix2pix/test_latest/images'\n",
    "target_folder = './results/RIVER_pix2pix/test_latest/submission'\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "for image_name in os.listdir(source_folder):\n",
    "    if 'fake' in image_name:\n",
    "        new_name = image_name.replace('_fake.png', '.jpg')\n",
    "        shutil.copy(os.path.join(source_folder, image_name), os.path.join(target_folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image as 428x240\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for image_name in os.listdir(target_folder):\n",
    "    img = cv2.imread(os.path.join(target_folder, image_name))\n",
    "    img = cv2.resize(img, (428, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(os.path.join(target_folder, image_name), img)\n",
    "print(\"Finished resizing images\")\n",
    "print(f\"Size: {len(os.listdir(target_folder))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the ROAD and RIVER submission\n",
    "\n",
    "Combine the ROAD and RIVER submission into the `./results/ROAD_RIVER_combined/submission` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_road_dir = './results/ROAD_pix2pix/test_latest/submission'\n",
    "source_river_dir = './results/RIVER_pix2pix/test_latest/submission'\n",
    "\n",
    "target_dir = './results/ROAD_RIVER_combined/submission'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "for image_name in os.listdir(source_road_dir):\n",
    "\tshutil.copy(os.path.join(source_road_dir, image_name), os.path.join(target_dir, image_name))\n",
    "for image_name in os.listdir(source_river_dir):\n",
    "\tshutil.copy(os.path.join(source_river_dir, image_name), os.path.join(target_dir, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size: {len(os.listdir(target_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the fake images\n",
    "shutil.make_archive(target_dir, 'zip', target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the results to AI CUP\n",
    "you should have the `submission.zip` file in the `./results/ROAD_RIVER_combined` folder\n",
    "\n",
    "submit the zip file to AI CUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
