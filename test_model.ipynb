{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./pytorch-CycleGAN-and-pix2pix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/littlefish/gen-ai-uav/pytorch-CycleGAN-and-pix2pix\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing data folder\n",
    "\n",
    "select the folder where the testing data is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './datasets/public_testing_dataset_1'\n",
    "# the directory may only contain `testA` subfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with the pre-trained model with single mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/public_testing_dataset_1/testA/\t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: ROAD_RIVER_pix2pix            \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \t[default: resnet_9blocks]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                 num_test: 1000                          \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from ./checkpoints/ROAD_RIVER_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/ROAD_RIVER_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000000.png']\n",
      "processing (0005)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000005.png']\n",
      "processing (0010)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000010.png']\n",
      "processing (0015)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000015.png']\n",
      "processing (0020)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000020.png']\n",
      "processing (0025)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000025.png']\n",
      "processing (0030)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000030.png']\n",
      "processing (0035)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000035.png']\n",
      "processing (0040)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000040.png']\n",
      "processing (0045)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000045.png']\n",
      "processing (0050)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000050.png']\n",
      "processing (0055)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000055.png']\n",
      "processing (0060)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000060.png']\n",
      "processing (0065)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000065.png']\n",
      "processing (0070)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000070.png']\n",
      "processing (0075)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000075.png']\n",
      "processing (0080)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000080.png']\n",
      "processing (0085)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000085.png']\n",
      "processing (0090)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000090.png']\n",
      "processing (0095)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000095.png']\n",
      "processing (0100)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000100.png']\n",
      "processing (0105)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000105.png']\n",
      "processing (0110)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000110.png']\n",
      "processing (0115)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000115.png']\n",
      "processing (0120)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000120.png']\n",
      "processing (0125)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000125.png']\n",
      "processing (0130)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000130.png']\n",
      "processing (0135)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000135.png']\n",
      "processing (0140)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000140.png']\n",
      "processing (0145)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000145.png']\n",
      "processing (0150)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000150.png']\n",
      "processing (0155)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000155.png']\n",
      "processing (0160)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000160.png']\n",
      "processing (0165)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000165.png']\n",
      "processing (0170)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000170.png']\n",
      "processing (0175)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000175.png']\n",
      "processing (0180)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000180.png']\n",
      "processing (0185)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000185.png']\n",
      "processing (0190)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000190.png']\n",
      "processing (0195)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000195.png']\n",
      "processing (0200)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000200.png']\n",
      "processing (0205)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000205.png']\n",
      "processing (0210)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000210.png']\n",
      "processing (0215)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000215.png']\n",
      "processing (0220)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000220.png']\n",
      "processing (0225)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000225.png']\n",
      "processing (0230)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000230.png']\n",
      "processing (0235)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000235.png']\n",
      "processing (0240)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000240.png']\n",
      "processing (0245)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000245.png']\n",
      "processing (0250)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000250.png']\n",
      "processing (0255)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000255.png']\n",
      "processing (0260)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000260.png']\n",
      "processing (0265)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000265.png']\n",
      "processing (0270)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000270.png']\n",
      "processing (0275)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000275.png']\n",
      "processing (0280)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000280.png']\n",
      "processing (0285)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000285.png']\n",
      "processing (0290)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000290.png']\n",
      "processing (0295)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000295.png']\n",
      "processing (0300)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000300.png']\n",
      "processing (0305)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000305.png']\n",
      "processing (0310)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000310.png']\n",
      "processing (0315)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000315.png']\n",
      "processing (0320)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000320.png']\n",
      "processing (0325)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000325.png']\n",
      "processing (0330)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000330.png']\n",
      "processing (0335)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000335.png']\n",
      "processing (0340)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000340.png']\n",
      "processing (0345)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000345.png']\n",
      "processing (0350)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000350.png']\n",
      "processing (0355)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RI_1000355.png']\n",
      "processing (0360)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000360.png']\n",
      "processing (0365)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000365.png']\n",
      "processing (0370)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000370.png']\n",
      "processing (0375)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000375.png']\n",
      "processing (0380)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000380.png']\n",
      "processing (0385)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000385.png']\n",
      "processing (0390)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000390.png']\n",
      "processing (0395)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000395.png']\n",
      "processing (0400)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000400.png']\n",
      "processing (0405)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000405.png']\n",
      "processing (0410)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000410.png']\n",
      "processing (0415)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000415.png']\n",
      "processing (0420)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000420.png']\n",
      "processing (0425)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000425.png']\n",
      "processing (0430)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000430.png']\n",
      "processing (0435)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000435.png']\n",
      "processing (0440)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000440.png']\n",
      "processing (0445)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000445.png']\n",
      "processing (0450)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000450.png']\n",
      "processing (0455)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000455.png']\n",
      "processing (0460)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000460.png']\n",
      "processing (0465)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000465.png']\n",
      "processing (0470)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000470.png']\n",
      "processing (0475)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000475.png']\n",
      "processing (0480)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000480.png']\n",
      "processing (0485)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000485.png']\n",
      "processing (0490)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000490.png']\n",
      "processing (0495)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000495.png']\n",
      "processing (0500)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000500.png']\n",
      "processing (0505)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000505.png']\n",
      "processing (0510)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000510.png']\n",
      "processing (0515)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000515.png']\n",
      "processing (0520)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000520.png']\n",
      "processing (0525)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000525.png']\n",
      "processing (0530)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000530.png']\n",
      "processing (0535)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000535.png']\n",
      "processing (0540)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000540.png']\n",
      "processing (0545)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000545.png']\n",
      "processing (0550)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000550.png']\n",
      "processing (0555)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000555.png']\n",
      "processing (0560)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000560.png']\n",
      "processing (0565)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000565.png']\n",
      "processing (0570)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000570.png']\n",
      "processing (0575)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000575.png']\n",
      "processing (0580)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000580.png']\n",
      "processing (0585)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000585.png']\n",
      "processing (0590)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000590.png']\n",
      "processing (0595)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000595.png']\n",
      "processing (0600)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000600.png']\n",
      "processing (0605)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000605.png']\n",
      "processing (0610)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000610.png']\n",
      "processing (0615)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000615.png']\n",
      "processing (0620)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000620.png']\n",
      "processing (0625)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000625.png']\n",
      "processing (0630)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000630.png']\n",
      "processing (0635)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000635.png']\n",
      "processing (0640)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000640.png']\n",
      "processing (0645)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000645.png']\n",
      "processing (0650)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000650.png']\n",
      "processing (0655)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000655.png']\n",
      "processing (0660)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000660.png']\n",
      "processing (0665)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000665.png']\n",
      "processing (0670)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000670.png']\n",
      "processing (0675)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000675.png']\n",
      "processing (0680)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000680.png']\n",
      "processing (0685)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000685.png']\n",
      "processing (0690)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000690.png']\n",
      "processing (0695)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000695.png']\n",
      "processing (0700)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000700.png']\n",
      "processing (0705)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000705.png']\n",
      "processing (0710)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000710.png']\n",
      "processing (0715)-th image... ['./datasets/public_testing_dataset_1/testA/PUB_RO_1000715.png']\n"
     ]
    }
   ],
   "source": [
    "! set -ex\n",
    "! python test.py --dataroot ./datasets/public_testing_dataset_1/testA/ --name ROAD_RIVER_pix2pix --model test --netG unet_256 --direction AtoB --dataset_mode single --norm batch --num_test 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the results into AI CUP format\n",
    "\n",
    "The results are stored in `./ROAD_pix2pix/test_latest/images/`.\n",
    "\n",
    "And there are 2 types of results:\n",
    "- `{Prefix}_real` (domainA)\n",
    "- `{Prefix}_fake` (domainB)\n",
    "\n",
    "Store the `{Prefix}_fake.png` as `{Prefix}.jpg` to `./ROAD_pix2pix/test_latest/submission/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fake images to the `./results/ROAD_RIVER_pix2pix/test_latest/submission/` folder\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "source_folder = './results/ROAD_RIVER_pix2pix/test_latest/images'\n",
    "target_folder = './results/ROAD_RIVER_pix2pix/test_latest/submission'\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "for image_name in os.listdir(source_folder):\n",
    "    if 'fake' in image_name:\n",
    "        new_name = image_name.replace('_fake.png', '.jpg')\n",
    "        shutil.copy(os.path.join(source_folder, image_name), os.path.join(target_folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 720\n"
     ]
    }
   ],
   "source": [
    "# resize the image as 420x240\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for image_name in os.listdir(target_folder):\n",
    "    img = cv2.imread(os.path.join(target_folder, image_name))\n",
    "    img = cv2.resize(img, (420, 240))\n",
    "    cv2.imwrite(os.path.join(target_folder, image_name), img)\n",
    "print(f\"Size: {len(os.listdir(target_folder))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/littlefish/gen-ai-uav/pytorch-CycleGAN-and-pix2pix/results/ROAD_RIVER_pix2pix/test_latest/submission.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the fake images\n",
    "shutil.make_archive(target_folder, 'zip', target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Method (2 domain-specific models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "dataset_zip = 'dataset/public_testing_dataset_1.zip'\n",
    "dataset_dir = 'dataset/public_testing_dataset_1'\n",
    "\n",
    "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess The Image to match the model input\n",
    "\n",
    "The label_img folder contains images `.png`, and all the images does not contains the ground truth, so we need to add the fake paired images, and concatenate to the original images to create the paired images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# source path\n",
    "dataset_label_img_dir = 'dataset/public_testing_dataset_1/label_img'\n",
    "# destination path\n",
    "# 2 folder: 1 for RIVER, 1 for ROAD\n",
    "public_test_road_dir = 'dataset/public_test_ROAD/test'\n",
    "public_test_river_dir = 'dataset/public_test_RIVER/test'\n",
    "\n",
    "# create destination directory if not exist\n",
    "if not os.path.exists(public_test_river_dir):\n",
    "\tos.makedirs(public_test_river_dir)\n",
    "if not os.path.exists(public_test_road_dir):\n",
    "\tos.makedirs(public_test_road_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each image in the source directory\n",
    "# and copy to destination directory\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "for filename in os.listdir(dataset_label_img_dir):\n",
    "\t# read the image\n",
    "\timg = cv2.imread(os.path.join(dataset_label_img_dir, filename))\n",
    "\n",
    "\t# concatenate the image with itself horizontally\n",
    "\timg_double = np.concatenate((img, img), axis=1)\n",
    "\n",
    "\t# determine the destination directory based on the filename\n",
    "\tif 'RI' in filename:\n",
    "\t\tdestination_dir = public_test_river_dir\n",
    "\telif 'RO' in filename:\n",
    "\t\tdestination_dir = public_test_road_dir\n",
    "\n",
    "\t# write the new image to the destination directory\n",
    "\tcv2.imwrite(os.path.join(destination_dir, filename), img_double)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the test folder to the model test input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./AI cup demo code/pytorch-CycleGAN-and-pix2pix/datasets/public_test_ROAD/test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source directory\n",
    "source_river_dir = './dataset/public_test_RIVER/test'\n",
    "source_road_dir = './dataset/public_test_ROAD/test'\n",
    "# Target directory\n",
    "target_dir = './AI cup demo code/pytorch-CycleGAN-and-pix2pix/datasets/'\n",
    "\n",
    "# copy the source folder to the target directory\n",
    "shutil.copytree(source_river_dir, os.path.join(target_dir, 'public_test_RIVER/test'))\n",
    "shutil.copytree(source_road_dir, os.path.join(target_dir, 'public_test_ROAD/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to the pix2pix code\n",
    "import os\n",
    "os.chdir('./pytorch-CycleGAN-and-pix2pix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/public_test_ROAD   \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: ROAD                          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 1000                          \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/ROAD/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/ROAD/test_latest\n",
      "processing (0000)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000360.png']\n",
      "processing (0005)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000365.png']\n",
      "processing (0010)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000370.png']\n",
      "processing (0015)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000375.png']\n",
      "processing (0020)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000380.png']\n",
      "processing (0025)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000385.png']\n",
      "processing (0030)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000390.png']\n",
      "processing (0035)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000395.png']\n",
      "processing (0040)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000400.png']\n",
      "processing (0045)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000405.png']\n",
      "processing (0050)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000410.png']\n",
      "processing (0055)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000415.png']\n",
      "processing (0060)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000420.png']\n",
      "processing (0065)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000425.png']\n",
      "processing (0070)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000430.png']\n",
      "processing (0075)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000435.png']\n",
      "processing (0080)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000440.png']\n",
      "processing (0085)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000445.png']\n",
      "processing (0090)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000450.png']\n",
      "processing (0095)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000455.png']\n",
      "processing (0100)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000460.png']\n",
      "processing (0105)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000465.png']\n",
      "processing (0110)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000470.png']\n",
      "processing (0115)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000475.png']\n",
      "processing (0120)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000480.png']\n",
      "processing (0125)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000485.png']\n",
      "processing (0130)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000490.png']\n",
      "processing (0135)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000495.png']\n",
      "processing (0140)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000500.png']\n",
      "processing (0145)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000505.png']\n",
      "processing (0150)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000510.png']\n",
      "processing (0155)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000515.png']\n",
      "processing (0160)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000520.png']\n",
      "processing (0165)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000525.png']\n",
      "processing (0170)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000530.png']\n",
      "processing (0175)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000535.png']\n",
      "processing (0180)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000540.png']\n",
      "processing (0185)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000545.png']\n",
      "processing (0190)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000550.png']\n",
      "processing (0195)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000555.png']\n",
      "processing (0200)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000560.png']\n",
      "processing (0205)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000565.png']\n",
      "processing (0210)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000570.png']\n",
      "processing (0215)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000575.png']\n",
      "processing (0220)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000580.png']\n",
      "processing (0225)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000585.png']\n",
      "processing (0230)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000590.png']\n",
      "processing (0235)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000595.png']\n",
      "processing (0240)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000600.png']\n",
      "processing (0245)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000605.png']\n",
      "processing (0250)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000610.png']\n",
      "processing (0255)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000615.png']\n",
      "processing (0260)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000620.png']\n",
      "processing (0265)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000625.png']\n",
      "processing (0270)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000630.png']\n",
      "processing (0275)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000635.png']\n",
      "processing (0280)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000640.png']\n",
      "processing (0285)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000645.png']\n",
      "processing (0290)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000650.png']\n",
      "processing (0295)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000655.png']\n",
      "processing (0300)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000660.png']\n",
      "processing (0305)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000665.png']\n",
      "processing (0310)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000670.png']\n",
      "processing (0315)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000675.png']\n",
      "processing (0320)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000680.png']\n",
      "processing (0325)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000685.png']\n",
      "processing (0330)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000690.png']\n",
      "processing (0335)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000695.png']\n",
      "processing (0340)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000700.png']\n",
      "processing (0345)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000705.png']\n",
      "processing (0350)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000710.png']\n",
      "processing (0355)-th image... ['./datasets/public_test_ROAD/test/PUB_RO_1000715.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/public_test_RIVER  \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: RIVER                         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 1000                          \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/RIVER/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/RIVER/test_latest\n",
      "processing (0000)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000000.png']\n",
      "processing (0005)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000005.png']\n",
      "processing (0010)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000010.png']\n",
      "processing (0015)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000015.png']\n",
      "processing (0020)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000020.png']\n",
      "processing (0025)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000025.png']\n",
      "processing (0030)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000030.png']\n",
      "processing (0035)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000035.png']\n",
      "processing (0040)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000040.png']\n",
      "processing (0045)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000045.png']\n",
      "processing (0050)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000050.png']\n",
      "processing (0055)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000055.png']\n",
      "processing (0060)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000060.png']\n",
      "processing (0065)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000065.png']\n",
      "processing (0070)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000070.png']\n",
      "processing (0075)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000075.png']\n",
      "processing (0080)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000080.png']\n",
      "processing (0085)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000085.png']\n",
      "processing (0090)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000090.png']\n",
      "processing (0095)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000095.png']\n",
      "processing (0100)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000100.png']\n",
      "processing (0105)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000105.png']\n",
      "processing (0110)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000110.png']\n",
      "processing (0115)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000115.png']\n",
      "processing (0120)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000120.png']\n",
      "processing (0125)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000125.png']\n",
      "processing (0130)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000130.png']\n",
      "processing (0135)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000135.png']\n",
      "processing (0140)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000140.png']\n",
      "processing (0145)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000145.png']\n",
      "processing (0150)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000150.png']\n",
      "processing (0155)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000155.png']\n",
      "processing (0160)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000160.png']\n",
      "processing (0165)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000165.png']\n",
      "processing (0170)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000170.png']\n",
      "processing (0175)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000175.png']\n",
      "processing (0180)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000180.png']\n",
      "processing (0185)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000185.png']\n",
      "processing (0190)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000190.png']\n",
      "processing (0195)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000195.png']\n",
      "processing (0200)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000200.png']\n",
      "processing (0205)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000205.png']\n",
      "processing (0210)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000210.png']\n",
      "processing (0215)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000215.png']\n",
      "processing (0220)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000220.png']\n",
      "processing (0225)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000225.png']\n",
      "processing (0230)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000230.png']\n",
      "processing (0235)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000235.png']\n",
      "processing (0240)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000240.png']\n",
      "processing (0245)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000245.png']\n",
      "processing (0250)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000250.png']\n",
      "processing (0255)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000255.png']\n",
      "processing (0260)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000260.png']\n",
      "processing (0265)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000265.png']\n",
      "processing (0270)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000270.png']\n",
      "processing (0275)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000275.png']\n",
      "processing (0280)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000280.png']\n",
      "processing (0285)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000285.png']\n",
      "processing (0290)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000290.png']\n",
      "processing (0295)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000295.png']\n",
      "processing (0300)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000300.png']\n",
      "processing (0305)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000305.png']\n",
      "processing (0310)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000310.png']\n",
      "processing (0315)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000315.png']\n",
      "processing (0320)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000320.png']\n",
      "processing (0325)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000325.png']\n",
      "processing (0330)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000330.png']\n",
      "processing (0335)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000335.png']\n",
      "processing (0340)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000340.png']\n",
      "processing (0345)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000345.png']\n",
      "processing (0350)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000350.png']\n",
      "processing (0355)-th image... ['./datasets/public_test_RIVER/test/PUB_RI_1000355.png']\n"
     ]
    }
   ],
   "source": [
    "# test the 2 models\n",
    "! python test.py --dataroot ./datasets/public_test_ROAD --name ROAD --model pix2pix --direction AtoB --num_test 1000\n",
    "! python test.py --dataroot ./datasets/public_test_RIVER --name RIVER --model pix2pix --direction AtoB --num_test 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 2160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size: {len(os.listdir('./results/ROAD/test_latest/images/'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the results into AI CUP format\n",
    "\n",
    "The results are stored in `./ROAD_pix2pix/test_latest/images/`.\n",
    "\n",
    "And there are 2 types of results: `real_A` and `fake_B`.\n",
    "\n",
    "The `real_A` is the original image, and the `fake_B` is the transformed image.\n",
    "\n",
    "Store the `{Prefix}_fake_B.png` as `{Prefix}.jpg` to `./ROAD_pix2pix/test_latest/submission/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fake images to the `./results/ROAD_RIVER_pix2pix/test_latest/submission/` folder\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "source_folder = './results/ROAD/test_latest/images'\n",
    "target_folder = './results/ROAD/test_latest/submission'\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "for image_name in os.listdir(source_folder):\n",
    "    if 'fake' in image_name:\n",
    "        new_name = image_name.replace('_fake_B.png', '.jpg')\n",
    "        shutil.copy(os.path.join(source_folder, image_name), os.path.join(target_folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image as 420x240\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for image_name in os.listdir(target_folder):\n",
    "    img = cv2.imread(os.path.join(target_folder, image_name))\n",
    "    img = cv2.resize(img, (420, 240))\n",
    "    cv2.imwrite(os.path.join(target_folder, image_name), img)\n",
    "print(f\"Size: {len(os.listdir(target_folder))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the fake images\n",
    "shutil.make_archive(target_folder, 'zip', target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the RIVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fake images to the `./results/ROAD_RIVER_pix2pix/test_latest/submission/` folder\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "source_folder = './results/RIVER/test_latest/images'\n",
    "target_folder = './results/RIVER/test_latest/submission'\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "for image_name in os.listdir(source_folder):\n",
    "    if 'fake' in image_name:\n",
    "        new_name = image_name.replace('_fake_B.png', '.jpg')\n",
    "        shutil.copy(os.path.join(source_folder, image_name), os.path.join(target_folder, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 360\n"
     ]
    }
   ],
   "source": [
    "# resize the image as 420x240\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for image_name in os.listdir(target_folder):\n",
    "    img = cv2.imread(os.path.join(target_folder, image_name))\n",
    "    img = cv2.resize(img, (420, 240))\n",
    "    cv2.imwrite(os.path.join(target_folder, image_name), img)\n",
    "print(f\"Size: {len(os.listdir(target_folder))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the ROAD and RIVER submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_road_dir = './results/ROAD/test_latest/submission'\n",
    "source_river_dir = './results/RIVER/test_latest/submission'\n",
    "\n",
    "target_dir = './results/submission'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "for image_name in os.listdir(source_road_dir):\n",
    "\tshutil.copy(os.path.join(source_road_dir, image_name), os.path.join(target_dir, image_name))\n",
    "for image_name in os.listdir(source_river_dir):\n",
    "\tshutil.copy(os.path.join(source_river_dir, image_name), os.path.join(target_dir, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/littlefish/gen-ai-uav/AI cup demo code/pytorch-CycleGAN-and-pix2pix/results/submission.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the fake images\n",
    "shutil.make_archive(target_dir, 'zip', target_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
