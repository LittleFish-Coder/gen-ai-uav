{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Train Pix2Pix model for image-to-image translation\n","\n","make sure you have done the dataset preparation before running this notebook. \n","\n","In this session, we will have 2 parts:\n","- Baseline Training\n","- Enhanced Training"]},{"cell_type":"markdown","metadata":{"id":"7wNjDKdQy35h"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1204,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"TRm-USlsHgEV","outputId":"93cc884a-52d9-4541-f9b5-8efe6096f00b"},"outputs":[],"source":["import os\n","\n","# check if `pytorch-CycleGAN-and-pix2pix` is already cloned\n","if not os.path.exists('pytorch-CycleGAN-and-pix2pix'):\n","\t!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"Pt3igws3eiVp"},"outputs":[],"source":["os.chdir('pytorch-CycleGAN-and-pix2pix/')"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270166,"status":"ok","timestamp":1710751377419,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"z1EySlOXwwoa","outputId":"c6e39497-644b-4194-8777-d69d971d726e"},"outputs":[],"source":["%pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{},"source":["# Basline model (train the road river in one model)"]},{"cell_type":"markdown","metadata":{"id":"8daqlgVhw29P"},"source":["## Datasets\n","\n","Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n","\n","(We have finished this part at the previous step when running `preprocess_dataset.ipynb`)\n","\n","Each dataset should have the following directory structure:\n","\n","```\n","datasets\n","└── training_dataset\n","\t├── train\n","\t├── test\n","```"]},{"cell_type":"markdown","metadata":{"id":"yFw1kDQBx3LN"},"source":["## Training (Baseline)\n","\n","official sample code: \n","\n","`python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction AtoB --display_id 0`\n","\n","- Change the `--dataroot` and `--name` to your own dataset's path and desired model's name. \n","\n","- `--model pix2pix` specifies the model type we want to train (the other is `cycle_gan`)\n","\n","- `--direction AtoB` (convert from domain A to domain B)\n","\n","- `--n_epochs 100` and `--n_epochs_decay 100` to train for 200 epochs(100 + 100)\n","\n","- `--display_id 0` to disable visdom display\n","\n","check `options/train_options.py` for more arguments options\n","\n","## some tips for enhancing :\n","[reference](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/760)\n","- `--netG resnet_9blocks` to adapt the image size\n","- `--preprocess none` to disable preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219031,"status":"ok","timestamp":1710751642502,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"0sp7TCT2x9dB","outputId":"dd4dbb3c-69a1-45e6-c307-837571389cff"},"outputs":[],"source":["# the below code train the full dataset in one stage (in which the model is trained on both the road and river images)\n","# use this line as baseline\n","! python train.py --dataroot ./datasets/training_dataset/ --name ROAD_RIVER_pix2pix --model pix2pix --direction AtoB --display_id 0\n","\n","# maybe better performance\n","# ! python train.py --dataroot ./datasets/training_dataset/ --name ROAD_RIVER_pix2pix --model pix2pix --direction AtoB --display_id 0 --netG resnet_9blocks --preprocess none \n","\n","# use nohup to run the training in the background\n","# ! nohup python train.py ... > train.log &"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","the results will be saved in `pytorch-CycleGAN-and-pix2pix/checkpoints/ROAD_RIVER_pix2pix` folder\n","\n","- `/web/index.html` for the visualization of the results\n","- `latest_net_G.pth` for the latest model"]},{"cell_type":"markdown","metadata":{},"source":["# Enhanced (train 2 domain-specific models)\n","- one for RIVER\n","- one for ROAD"]},{"cell_type":"markdown","metadata":{},"source":["## Datasets\n","\n","Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n","\n","(We have finished this part at the previous step when running `preprocess_dataset.ipynb`)\n","\n","Each dataset should have the following directory structure:\n","\n","```\n","datasets\n","└── train_ROAD\n","    ├── train\n","    ├── test\n","└── train_RIVER\n","    ├── train\n","    ├── test\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Training (Enhanced)\n","Add argument:\n","- `--n_epochs=200 (default 100)`\n","- `--n_epochs_decay=200 (default 100)`\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# add the n_epochs and n_epochs_decay parameters up to total 400 epochs for each model\n","! python train.py --dataroot ./datasets/train_ROAD --name ROAD_pix2pix --model pix2pix --direction AtoB --n_epochs 500 --n_epochs_decay 100 --display_id 0 --epoch_count 401 --continue_train\n","! python train.py --dataroot ./datasets/train_RIVER --name RIVER_pix2pix --model pix2pix --direction AtoB --n_epochs 500 --n_epochs_decay 100 --display_id 0 --epoch_count 401 --continue_train\n","\n","# use nohup to run the training in the background\n","# ! nohup python train.py ... > road.log &\t\n","# ! nohup python train.py ... > river.log &"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","after training, you can find the results in \n","- `pytorch-CycleGAN-and-pix2pix/checkpoints/ROAD_pix2pix` folder\n","- `pytorch-CycleGAN-and-pix2pix/checkpoints/RIVER_pix2pix` folder\n","\n","Each folder contains:\n","- `/web/index.html` for the visualization of the results\n","- `latest_net_G.pth` for the latest model"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
