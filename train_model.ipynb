{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"7wNjDKdQy35h"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1204,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"TRm-USlsHgEV","outputId":"93cc884a-52d9-4541-f9b5-8efe6096f00b"},"outputs":[],"source":["import os\n","\n","# check if `pytorch-CycleGAN-and-pix2pix` is already cloned\n","if not os.path.exists('pytorch-CycleGAN-and-pix2pix'):\n","\t!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710751107262,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"Pt3igws3eiVp"},"outputs":[],"source":["os.chdir('pytorch-CycleGAN-and-pix2pix/')"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270166,"status":"ok","timestamp":1710751377419,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"z1EySlOXwwoa","outputId":"c6e39497-644b-4194-8777-d69d971d726e"},"outputs":[],"source":["%pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"8daqlgVhw29P"},"source":["# Datasets\n","\n","Put the dataset in the `pytorch-CycleGAN-and-pix2pix/datasets` folder\n","\n","(We have finished this part at the previous step when running `preprocess_dataset.ipynb`)\n","\n","Each dataset should have the following directory structure:\n","\n","```\n","datasets\n","└── training_dataset\n","\t├── train\n","\t├── test\n","```"]},{"cell_type":"markdown","metadata":{"id":"yFw1kDQBx3LN"},"source":["# Training (Baseline)\n","\n","`python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction AtoB --display_id 0`\n","\n","- Change the `--dataroot` and `--name` to your own dataset's path and model's name. \n","\n","- `--model pix2pix` specifies the model we want to train\n","\n","- `--direction AtoB` (convert from domain A to domain B)\n","\n","- `--n_epochs 100` and `--n_epochs_decay 100` to train for 200 epochs(100 + 100)\n","\n","- `--display_id 0` to disable visdom display\n","\n","check `options/train_options.py` for more arguments options"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219031,"status":"ok","timestamp":1710751642502,"user":{"displayName":"D Parejo","userId":"17109521203490422964"},"user_tz":-480},"id":"0sp7TCT2x9dB","outputId":"dd4dbb3c-69a1-45e6-c307-837571389cff"},"outputs":[],"source":["# the below code train the full dataset in one stage (in which the model is trained on both the road and river images)\n","# use this line as baseline\n","! python train.py --dataroot ./datasets/training_dataset/ --name ROAD_RIVER_pix2pix --model pix2pix --direction AtoB --display_id -1\n","\n","# use nohup to run the training in the background\n","# ! nohup python train.py ... &"]},{"cell_type":"markdown","metadata":{},"source":["# Train 2 domain-specific models (Enhanced)\n","- one for RIVER\n","- one for ROAD\n","\n","Add argument:\n","- `--n_epochs=200 (default 100)`\n","- `--n_epochs_decay=200 (default 100)`\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ! python train.py --dataroot ./datasets/ROAD --name ROAD_pix2pix --model pix2pix --direction AtoB --n_epochs 200 --n_epochs_decay 200 --display_id 0\n","# ! python train.py --dataroot ./datasets/RIVER --name RIVER_pix2pix --model pix2pix --direction AtoB --n_epochs 200 --n_epochs_decay 200 --display_id 0\n","\n","# use nohup to run the training in the background\n","# ! nohup python train.py ... > road.log &\t# for ROAD\n","# ! nohup python train.py ... > river.log &\t# for RIVER\n","\n","# Recording use:\n","# [1] 44276\n","# [2] 45562"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
